# Inline AI

Add AI capabilities directly into your Obsidian notes. Write questions, reference documents, include imagesâ€”and get AI responses inline.

## âœ¨ Features

- **Native [[Links]]** â€” Just use `[[Note Name]]` to include document contentâ€”no special syntax needed
- **5 AI Providers** â€” Anthropic (Claude), OpenAI (GPT), Google (Gemini), DeepSeek, Perplexity
- **50+ Built-in Models** â€” From GPT-4o to Claude Opus 4.5, Gemini 3.0, and more
- **Vision Support** â€” Include images for visual AI models
- **PDF Support** â€” Native PDF handling with Claude and Gemini
- **Tool Use** â€” AI can read and create notes in your vault
- **Extended Thinking** â€” Enable reasoning modes for complex tasks
- **Token & Cost Tracking** â€” See token usage and estimated costs per response
- **Quick Commands** â€” Insert all tags via the Command Palette

---

## ğŸš€ Quick Start

### 1. Install the Plugin

**Option A: Community Plugins (Coming Soon)**

Once approved, search for "Inline AI" in Settings â†’ Community Plugins â†’ Browse.

**Option B: BRAT (Beta Testing)**

1. Install [BRAT](https://github.com/TfTHacker/obsidian42-brat) from Community Plugins
2. Open Settings â†’ BRAT â†’ "Add Beta Plugin"
3. Enter: `Maximophone/obsidian-ai-plugin`
4. Enable the plugin in Community Plugins

**Option C: Manual Download**

1. Go to the [latest release](https://github.com/Maximophone/obsidian-ai-plugin/releases/latest)
2. Download `main.js`, `manifest.json`, and `styles.css`
3. Create folder: `YourVault/.obsidian/plugins/inline-ai/`
4. Move the 3 files into that folder
5. Restart Obsidian and enable the plugin in Settings â†’ Community Plugins

**Option D: Build from Source**

```bash
git clone https://github.com/Maximophone/obsidian-ai-plugin.git
cd obsidian-ai-plugin
npm install && npm run build
```

Copy `main.js`, `manifest.json`, and `styles.css` to your vault's `.obsidian/plugins/inline-ai/` folder.

### 2. Add Your API Key

Open **Settings â†’ Obsidian AI** and add at least one API key.

### 3. Start Using It

The easiest way to use the plugin is through **Commands**:

1. Press `Cmd+P` (or `Ctrl+P`) to open the Command Palette
2. Type "Obsidian AI" to see all available commands
3. Select a command to insert the appropriate tag

Or type `/` in your note to access commands directly!

---

## ğŸ“ Using Commands (Recommended)

Commands are the fastest way to insert AI tags. Open the Command Palette (`Cmd+P`) and search for:

| Command | What It Does |
|---------|--------------|
| **Insert AI block** | Creates an AI conversation block |
| **Insert reply tag** | Triggers AI response |
| **Insert model tag** | Opens model selector |
| **Insert document reference** | Pick a note to include |
| **Insert file tag** | Pick any file to include |
| **Insert image tag** | Pick an image for vision |
| **Insert PDF tag** | Pick a PDF document |
| **Insert prompt tag** | Select from your prompts folder |
| **Insert tools tag** | Enable AI tool use |
| **Insert think tag** | Enable extended thinking |
| **Insert debug tag** | Show detailed API logs |
| **Insert mock tag** | Test without API calls |
| **Insert URL tag** | Fetch webpage content |
| **Insert system prompt** | Set system instructions |
| **Insert inline tag** | Include all linked notes |

---

## ğŸ’¬ Basic Usage

### Simple Question

```markdown
<ai!>
What are the main principles of good note-taking?
<reply!>
</ai!>
```

Save the file â†’ AI response appears where `<reply!>` was:

```markdown
<ai!>
What are the main principles of good note-taking?
|AI|
The main principles include:
1. Be concise but complete...
|/AI|
</ai!>
```

### Choose a Model

```markdown
<ai!>
<model!gpt4o>
Explain quantum computing simply.
<reply!>
</ai!>
```

### Include Context

**Link to notes directly** (recommended):
```markdown
<ai!>
Compare the ideas in [[Project A]] and [[Project B]].
<reply!>
</ai!>
```

Just use standard Obsidian `[[links]]`â€”the content is automatically included! This is the easiest way to give context to the AI.

**Current document:**
```markdown
<ai!>
<this!>
Summarize the above content.
<reply!>
</ai!>
```

**Any file (outside vault):**
```markdown
<ai!>
<file!"/path/to/config.json">
Explain this configuration.
<reply!>
</ai!>
```

---

## ğŸ–¼ï¸ Vision & Documents

### Images

Use vision-capable models (GPT-4o, Claude, Gemini) to analyze images:

```markdown
<ai!>
<model!gpt4o>
<image!"/path/to/screenshot.png">
What's shown in this screenshot?
<reply!>
</ai!>
```

### PDFs

Claude and Gemini can read PDFs natively:

```markdown
<ai!>
<model!sonnet4>
<pdf!"/path/to/paper.pdf">
Summarize the key findings.
<reply!>
</ai!>
```

### URLs

Fetch and include webpage content:

```markdown
<ai!>
<url!"https://example.com/article">
What are the main points?
<reply!>
</ai!>
```

---

## ğŸ› ï¸ Tool Use

Enable AI to interact with your vault:

```markdown
<ai!>
<tools!obsidian>
Search my vault for notes about "project planning" and summarize what you find.
<reply!>
</ai!>
```

### Available Tools

**Read-only** (automatic):
- `list_vault` â€” Browse folders
- `read_note` â€” Read note content
- `search_vault` â€” Find notes by content
- `get_backlinks` â€” Find linked notes
- And more...

**Write tools** (require confirmation):
- `create_note` â€” Create new notes

When the AI tries to create or modify content, you'll see a confirmation dialog.

---

## ğŸ§  Extended Thinking

Enable reasoning mode for complex problems:

```markdown
<ai!>
<model!sonnet4>
<think!>
Solve this logic puzzle step by step...
<reply!>
</ai!>
```

Specify a token budget for thinking:

```markdown
<ai!>
<think!50000>
...
</ai!>
```

---

## ğŸ”§ Debugging

### Debug Mode

See exactly what's sent to the API:

```markdown
<ai!>
<debug!>
Why isn't this working?
<reply!>
</ai!>
```

### Mock Mode

Test your setup without making API calls:

```markdown
<ai!>
<mock!>
This will echo the request parameters.
<reply!>
</ai!>
```

---

## ğŸ“‹ All Tags Reference

| Tag | Purpose | Example |
|-----|---------|---------|
| `<ai!>...</ai!>` | AI conversation block | `<ai!>content</ai!>` |
| `<reply!>` | Trigger AI response | `<reply!>` |
| `<model!name>` | Select model | `<model!gpt4o>` |
| `<system!"prompt">` | System instructions | `<system!"Be concise">` |
| `<this!>` | Include current document | `<this!>` |
| `[[Note]]` | Include vault note (auto) | `[[My Note]]` |
| `<doc!"[[Note]]">` | Include vault note (explicit) | `<doc!"[[My Note]]">` |
| `<file!"/path">` | Include any file | `<file!"/tmp/data.txt">` |
| `<image!"/path">` | Include image | `<image!"/img.png">` |
| `<pdf!"/path">` | Include PDF | `<pdf!"/doc.pdf">` |
| `<url!"url">` | Fetch webpage | `<url!"https://...">` |
| `<prompt!"name">` | Load saved prompt | `<prompt!"coding">` |
| `<tools!name>` | Enable tool use | `<tools!obsidian>` |
| `<think!>` | Extended thinking | `<think!50000>` |
| `<debug!>` | Show API details | `<debug!>` |
| `<mock!>` | Test without API | `<mock!>` |
| `<inline!>` | Include all [[links]] (on by default) | `<inline!>` |
| `<help!>` | Show help | `<help!>` |
| `<temperature!n>` | Set temperature | `<temperature!0.5>` |
| `<max_tokens!n>` | Set max tokens | `<max_tokens!8000>` |

---

## ğŸ¤– Available Models

### Anthropic (Claude)
`haiku`, `sonnet4`, `sonnet45`, `opus4`, `opus45`

### OpenAI
`gpt4o`, `gpt4turbo`, `gpt5`, `gpt5.1`, `gpt5.2`, `o1`, `o3`, `o4-mini`

### Google (Gemini)
`gemini`, `gemini2.5pro`, `gemini2.5flash`, `gemini3pro`

### DeepSeek
`deepseek`, `deepseek-reasoner`

### Perplexity
`sonar`, `sonar-pro`, `sonar-deep`

### Direct Format
Specify any model: `<model!anthropic:claude-3-opus-20240229>`

---

## âš™ï¸ Configuration

Open **Settings â†’ Obsidian AI** to configure:

- **API Keys** â€” Add keys for each provider you want to use
- **Default Model** â€” Model to use when not specified
- **Temperature** â€” Response randomness (0-1)
- **Max Tokens** â€” Maximum response length
- **Prompts Folder** â€” Where to find your prompt files
- **Inline Linked Notes** â€” Automatically include `[[linked]]` note content (enabled by default)
- **Show Token Count** â€” Display token usage in AI responses

---

## ğŸ’° Token & Cost Tracking

Each AI response shows token usage and an estimated cost:

```
**ğŸ¤– Assistant** Â· `sonnet4` Â· *12.5k in* Â· *834 out* Â· *$0.06*
```

This displays:
- **Model** â€” The model alias used for this response
- **Tokens in** â€” Input tokens (your messages + context)
- **Tokens out** â€” Output tokens (AI response)
- **Cost** â€” Estimated cost in USD

### Important Notes

âš ï¸ **Rough Estimation** â€” The cost shown is an approximation based on published API pricing. Actual costs may vary slightly.

âš ï¸ **Cumulative Cost** â€” The cost displayed represents the cumulative cost of the entire conversation up to that point, assuming you used the same model throughout. If you switch models mid-conversation, the cost estimate will not be accurate since it calculates based on the current model's pricing for all tokens.

âš ï¸ **Not All Models** â€” Cost estimates are only available for models with known pricing. If a model doesn't have pricing data, no cost will be shown.

To enable token counting, go to **Settings â†’ Obsidian AI â†’ Show Token Count**.

---

## ğŸ”¨ Development

### Hot Reload Setup

```bash
# Symlink to your vault
ln -s /path/to/obsidian-ai-plugin /path/to/vault/.obsidian/plugins/obsidian-ai

# Install Hot Reload plugin in Obsidian

# Run dev build
npm run dev
```

Changes auto-rebuild and auto-reload!

---

## ğŸ“œ Credits

This plugin is a TypeScript port of [obsidian_ai](https://github.com/Maximophone/obsidian_ai), originally written in Python.

## License

MIT License
